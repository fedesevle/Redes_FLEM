{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "directorio='G:\\\\Redes\\\\'\n",
    "#directorio='C:\\\\Users\\\\Usuario\\\\Documents\\\\GitHub\\\\Red\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "version=2\n",
    "paper_conjuntos = []\n",
    "\n",
    "#Saca el campo del diccionario\n",
    "def sacarcampo(paper,key):\n",
    "    if key in paper:\n",
    "        del paper[key]\n",
    "\n",
    "#Filtra papers, saca campos innecesarios y guarda en archivo \"papers_filtro_n.txt\"\n",
    "def agregarpaper(R_n,paper_conjuntos):\n",
    "    paper_conjuntos = []\n",
    "    \n",
    "    with open(directorio+'papers_filtrados'+str(version)+'.txt', 'a',encoding='utf_8') as archivo_guardar:\n",
    "         \n",
    "    #archivo_guardar = open('C:\\\\Users\\\\Usuario\\\\Documents\\\\GitHub\\\\Red\\\\papers_filtro_'+str(version)+'.txt','a',encoding='utf-8') \n",
    "    \n",
    "        R = open('G:\\Redes\\mag_papers_'+R_n+'.txt', 'r') \n",
    "        N = 999999\n",
    "        i = 0\n",
    "        for line in R:\n",
    "            paper=ast.literal_eval(line)\n",
    "            try:\n",
    "                paper['doc_type']\n",
    "                paper['fos']\n",
    "                paper['keywords']\n",
    "                paper['references']\n",
    "                paper['venue']\n",
    "                if paper['doc_type']=='Journal' and paper['lang']=='en':\n",
    "                    paper_conjuntos.append(paper)\n",
    "                    key='abstract';sacarcampo(paper,key)\n",
    "                    key='url';sacarcampo(paper,key)\n",
    "                    key='lang';sacarcampo(paper,key)\n",
    "                    key='page_start';sacarcampo(paper,key)\n",
    "                    key='page_end';sacarcampo(paper,key)\n",
    "                    key='doc_type';sacarcampo(paper,key)\n",
    "                    key='pdf';sacarcampo(paper,key)\n",
    "                    json.dump(paper, archivo_guardar, ensure_ascii=True)\n",
    "                    archivo_guardar.write('\\n')\n",
    "            except KeyError:\n",
    "                pass\n",
    "            i+=1\n",
    "            if i==N:\n",
    "                break\n",
    "        R.close()\n",
    "    archivo_guardar.close()\n",
    "    return(paper_conjuntos)\n",
    "\n",
    "#Crea lista de papers filtrados y diccionario de papers citados y su frecuencia\n",
    "def contador(ides_in,ides_out,paper_conjuntos):\n",
    "    for line in range(len(paper_conjuntos)):\n",
    "        ides_out.append(paper_conjuntos[line]['id'])\n",
    "        a=paper_conjuntos[line]['references']\n",
    "        for tag in range(len(a)):\n",
    "            try:\n",
    "                b=ides_in[a[tag]]\n",
    "                b+=1\n",
    "                ides_in.update({a[tag]:b})\n",
    "            except:\n",
    "                ides_in[a[tag]]=1\n",
    "    return(ides_in)\n",
    "\n",
    "#Crea el archivo de papers filtrados, la lista y el diccionario de frecuencias de citas\n",
    "def agregar_contar(ides_in,ides_out,R_n,paper_conjuntos):\n",
    "    paper_conjuntos=agregarpaper(R_n,paper_conjuntos)\n",
    "    ides_in=contador(ides_in,ides_out,paper_conjuntos)\n",
    "    return(ides_in,ides_out)\n",
    "    \n",
    "ides_out=[]\n",
    "ides_in={}\n",
    "for i in range(20,25):\n",
    "    ides_in,ides_out=agregar_contar(ides_in,ides_out,str(i),[])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131644\n"
     ]
    }
   ],
   "source": [
    "interseccion=(set(ides_out).intersection(list(ides_in.keys())))\n",
    "print(len(interseccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interseccion_archivo = open(directorio+'papers_filtro_'+str(version)+'.txt','a',encoding='utf-8') \n",
    "for i in interseccion:\n",
    "    interseccion_archivo.write(i)\n",
    "interseccion_archivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "paper_conjuntos = []\n",
    "R = open(directorio+'papers_filtrados'+str(version)+'.txt', 'r',encoding='utf_8') \n",
    "archivo_red = open(directorio+'archivo_red_'+str(version)+'.txt','a',encoding='utf-8')\n",
    "archivo_year = open(directorio+'archivo_year_'+str(version)+'.txt','a',encoding='utf-8')\n",
    "archivo_venue = open(directorio+'archivo_venue_'+str(version)+'.txt','a',encoding='utf-8')\n",
    "archivo_fos = open(directorio+'archivo_fos_'+str(version)+'.txt','a',encoding='utf-8')\n",
    "archivo_keywords = open(directorio+'archivo_keywords_'+str(version)+'.txt','a',encoding='utf-8')\n",
    "archivo_name = open(directorio+'archivo_name_'+str(version)+'.txt','a',encoding='utf-8')\n",
    "archivo_org = open(directorio+'archivo_org_'+str(version)+'.txt','a',encoding='utf-8')\n",
    "for line in R:\n",
    "    i+=1\n",
    "    paper=ast.literal_eval(line)\n",
    "    if paper['id'] in interseccion:\n",
    "        archivo_year.write(str(paper['id'])+' '+str(paper['year']))\n",
    "        archivo_year.write('\\n')\n",
    "        archivo_fos.write(str(paper['id'])+' '+str(paper['fos']))\n",
    "        archivo_fos.write('\\n')\n",
    "        archivo_venue.write(str(paper['id'])+' '+str(paper['venue']))\n",
    "        archivo_venue.write('\\n')\n",
    "        try:\n",
    "            archivo_keywords.write(paper['id']+' '+str(paper['keywords']))\n",
    "            archivo_keywords.write('\\n')\n",
    "        except KeyError:\n",
    "            pass\n",
    "        try:\n",
    "            archivo_name.write(paper['id']+' '+paper['authors'][0]['name'])\n",
    "            archivo_name.write('\\n')\n",
    "        except KeyError:\n",
    "            pass\n",
    "        try:\n",
    "            archivo_org.write(paper['id']+' '+paper['authors'][0]['org'])\n",
    "            archivo_org.write('\\n')\n",
    "        except KeyError:\n",
    "            pass\n",
    "        for cita in paper['references']:\n",
    "            if cita in interseccion:\n",
    "                archivo_red.write(str(paper['id'])+' '+cita)\n",
    "                archivo_red.write('\\n')\n",
    "R.close()\n",
    "archivo_red.close()\n",
    "archivo_year.close()\n",
    "archivo_venue.close()\n",
    "archivo_fos.close()\n",
    "archivo_keywords.close()\n",
    "archivo_name.close()\n",
    "archivo_org.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
